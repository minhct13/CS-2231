{"topic": "<ul class=\"tags\">\n<a class=\"tag\" href=\"https://machinelearningcoban.com/tags#Keras,\">Keras,</a>\n<a class=\"tag\" href=\"https://machinelearningcoban.com/tags#mlp\">mlp</a>\n</ul>", "title": "<h1 class=\"post-title\" itemprop=\"name\">Bài 36. Giới thiệu về Keras</h1>", "introduction": {"title": "<h2 id=\"1-giới-thiệu\">1. Giới thiệu</h2>", "content": "<p>Kể từ 2012 khi <a href=\"https://machinelearningcoban.com/2018/06/22/deeplearning/#dot-pha-\">deep learning có bước đột phá lớn</a>, hàng loạt các thư viện hỗ trợ deep learning ra đời. Cùng với đó, ngày càng nhiều kiến trúc deep learning ra đời, khiến cho số lượng ứng dụng và các bài báo liên quan tới deep learning tăng lên chóng mặt.</p><p>Các thư viện deep learning thường được ‘chống lưng’ bởi những hãng công nghệ lớn: Google (Keras, TensorFlow), Facebook (Caffe2, Pytorch), Microsoft (CNTK), Amazon (Mxnet), Microsoft và Amazon cũng đang bắt tay xây dựng Gluon (phiên bản tương tự như Keras). (Các hãng này đều có các dịch vụ cloud computing và muốn thu hút người dùng).</p><hr/><div class=\"imgcap\">\n<div>\n<img src=\"./ex19_files/dlp0.png\" width=\"600\"/>\n</div>\n<div class=\"thecap\">Các thư viện deep learning và các hãng công nghệ lớn. <br/> (Nguồn: <a href=\"https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750\">Battle of the Deep Learning frameworks — Part I: 2017, even more frameworks and interfaces</a>)</div>\n</div><hr/><p>Vậy thư viện nào là tốt nhất? Câu trả lời tuỳ thuộc vào việc bạn quen với hệ điều hành, ngôn ngữ lập trình nào, bạn sử dụng deep learning vào mục đích nghiên cứu hay ra sản phẩm, bạn sử dụng trên nền tảng phần cứng nào, v.v.</p><p>Nhìn chung, một thư viện deep learning tốt cần có các đặc điểm sau:</p><ol>\n<li>\n<p>Hỗ trợ tính toán với GPU và các hệ thống phân tán. Điều này là tối quan trọng vì việc huấn luyện các mô hình deep learning yêu cầu khả năng tính toán rất mạnh.</p>\n</li>\n<li>\n<p>Hỗ trợ các ngôn ngữ lập trình phổ biến: C/C++, Python, Java, R, …</p>\n</li>\n<li>\n<p>Có thể chạy được trên nhiều hệ điều hành.</p>\n</li>\n<li>\n<p>Thời gian từ ý tưởng tới xây dựng và huấn luyện mô hình ngắn.</p>\n</li>\n<li>\n<p>Có thể chạy trên trình duyệt và các thiết bị di động.</p>\n</li>\n<li>\n<p>Có khả năng giúp người lập trình can thiệp sâu vào mô hình và tạo ra các mô hình phức tạp.</p>\n</li>\n<li>\n<p>Chứa nhiều <code class=\"language-plaintext highlighter-rouge\">model zoo</code>, tức các mô hình deep learning thông dụng đã được huấn luyện.</p>\n</li>\n<li>\n<p>Hỗ trợ tính toán backpropagation tự động.</p>\n</li>\n<li>\n<p>Có cộng đồng hỏi đáp lớn.</p>\n</li>\n</ol><p>Thật khó có thể chỉ ra một thư viện đáp ứng tốt tất cả các yêu cầu phía trên. Các bạn có thể xem các bài so sánh các thư viện này ở phần <a href=\"https://machinelearningcoban.com/2018/07/06/deeplearning/#-tai-lieu-tham-khao\">Tài liệu tham khảo</a>. Tôi chỉ xin giới thiệu một vài thống kê giúp các bạn có cái nhìn nhanh nhất về thư viện nào được sử dụng nhiều nhất.</p><hr/><div class=\"imgcap\">\n<div>\n<img src=\"./ex19_files/dlp1.png\" width=\"600\"/>\n</div>\n<div class=\"thecap\">Số lượng 'stars' trên GitHub repo. <br/> (Xem thêm: <a href=\"https://blog.paperspace.com/which-ml-framework-should-i-use/\">Machine Learning Frameworks Comparison</a>)</div>\n</div><ol>\n<li>TensorFlow, 2. Caffe (năm 2015-2016).</li>\n</ol><hr/><hr/><div class=\"imgcap\">\n<div>\n<img src=\"./ex19_files/dlp2.jpg\" width=\"600\"/>\n</div>\n<div class=\"thecap\">Số lượng 'stars' trên GitHub repo, số lượng 'contributors', và 'tuổi' của thư viện. <br/> (Xem thêm: <a href=\"https://blog.paperspace.com/which-ml-framework-should-i-use/\">Top 16 Open Source Deep Learning Libraries and Platforms</a>)</div>\n</div><ol>\n<li>TensorFlow, 2. Keras, 3. Caffe</li>\n</ol><hr/><hr/><div class=\"imgcap\">\n<div>\n<img src=\"./ex19_files/dlp3.png\" width=\"600\"/>\n</div>\n<div class=\"thecap\">Số lượng các bài báo trên arxiv có đề cập đến mỗi thư viện. <br/> (Xem thêm: <a href=\"https://keras.io/why-use-keras/\">Why use Keras?</a>)</div>\n</div><ol>\n<li>TensorFlow, 2. Keras, 3. Caffe</li>\n</ol><hr/><p>Những so sánh trên đây chỉ ra rằng TensorFlow, Keras và Caffe là các thư viện được sử dụng nhiều nhất (gần đây có thêm PyTorch rất dễ sử dụng và đang thu hút thêm nhiều người dùng).</p><p>Keras được coi là một thư viện ‘high-level’ với phần ‘low-level’ (còn được gọi là <em>backend</em>) có thể là TensorFlow, CNTK, hoặc Theano (<a href=\"https://syncedreview.com/2017/09/29/rip-theano/\">sắp tới Theano sẽ không được duy trì nâng cấp nữa</a>). Keras có cú pháp đơn giản hơn TensorFlow rất nhiều. Với mục đích giới thiệu về các mô hình nhiều hơn là các sử dụng các thư viện deep learning, tôi sẽ chọn Keras với TensorFlow là ‘backend’.</p><p>(Bản thân tôi khi làm nghiên cứu thường dùng TensorFlow và Pytorch.)</p><p>Các bạn có thể đọc thêm bài <a href=\"https://keras.io/why-use-keras/\">Why use Keras?</a> trên trang chủ của Keras (<em>Tất nhiên trên trang chủ của thư viện nào cũng sẽ có một bài tương tự kiểu ‘Why use …?’</em>). Tôi xin nêu lại một vài gạch đầu dòng:</p><ul>\n<li>\n<p>Keras ưu tiên  trải nghiệm của người lập trình</p>\n</li>\n<li>\n<p>Keras đã được sử dụng rộng rãi trong doanh nghiệp và cộng đồng nghiên cứu</p>\n</li>\n<li>\n<p>Keras giúp dễ dàng biến các thiết kế thành sản phẩm</p>\n</li>\n<li>\n<p>Keras hỗ trợ huấn luyện trên nhiều GPU phân tán</p>\n</li>\n<li>\n<p>Keras hỗ trợ đa backend engines và không giới hạn bạn vào một hệ sinh thái</p>\n</li>\n</ul><p>Amazon hiện cũng đang làm việc để phát triển MXNet backend cho Keras.\nMô hình Keras có thể được huấn luyện trên một số nền tảng phần cứng khác nhau ngoài CPU:</p><ul>\n<li>NVIDIA GPU</li>\n<li>Google TPUs, thông qua TensorFlow backend và Google Cloud</li>\n<li>Các OpenCL GPU, chẳng hạn như các sảm phầm từ AMD, thông qua PlaidML Keras backend.</li>\n</ul><p>Hy vọng chừng đó đã đủ để chúng ta cùng bắt đầu với Keras. Cách cài đặt Keras có thể được tìm thấy trên <a href=\"https://keras.io/\">trang chủ của nó</a>.</p><p>Tiếp theo, chúng ta sẽ làm quen với Keras qua ba ví dụ đơn giản: <a href=\"https://machinelearningcoban.com/2016/12/28/linearregression/\">linear regression</a>, <a href=\"https://machinelearningcoban.com/2017/01/27/logisticregression/\">logistic regression</a>, và <a href=\"https://machinelearningcoban.com/2017/02/24/mlp/\">multi-layer perceptron</a>.</p><p><a name=\"-linear-regression-va-logistic-regression-voi-keras\"></a></p>"}, "formulas": {"title": "<h2 id=\"2-linear-regression-và-logistic-regression-với-keras\">2. Linear regression và logistic regression với Keras</h2>", "content": "<hr/><p>Việc huấn luyện một mô hình deep learning hay neural network nói chung bao gồm các bước:</p><ol>\n<li>Chuẩn bị dữ liệu</li>\n<li>Xây dựng network</li>\n<li>Chọn thuật toán cập nhật nghiệm, xây dựng loss và phương pháp đánh giá mô hình</li>\n<li>Huấn luyện mô hình.</li>\n<li>Đánh giá mô hình</li>\n</ol><hr/><p>Chúng ta cùng xem Keras thực hiện các bước này thông qua hai ví dụ dưới đây.</p><p><a name=\"-keras-voi-linear-regression\"></a></p><h3 id=\"21-keras-với-linear-regression\">2.1. Keras với linear regression</h3><p>Ta cùng làm một ví dụ đơn giản. Dữ liệu đầu <code class=\"language-plaintext highlighter-rouge\">X</code> vào có số chiều là 2, đầu ra <code class=\"language-plaintext highlighter-rouge\">y = 2*X[0] + 3*X[1] + 4 + e</code> với <code class=\"language-plaintext highlighter-rouge\">e</code> là nhiễu tuân theo một phân phối chuẩn có kỳ vọng bằng 0, phương sai bằng 0.2.</p><p>Dưới đây là đoạn code ví dụ về huấn luyện mô hình linear regression bằng Keras:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span> \n<span class=\"kn\">from</span> <span class=\"nn\">keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Sequential</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.layers.core</span> <span class=\"kn\">import</span> <span class=\"n\">Dense</span><span class=\"p\">,</span> <span class=\"n\">Activation</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">optimizers</span>\n\n<span class=\"c1\"># 1. create pseudo data y = 2*x0 + 3*x1 + 4\n</span><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span>  <span class=\"mi\">2</span><span class=\"o\">*</span> <span class=\"n\">X</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">X</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"p\">.</span><span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)</span> <span class=\"c1\"># noise added\n</span>\n<span class=\"c1\"># 2. Build model \n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">([</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'linear'</span><span class=\"p\">)])</span>\n\n<span class=\"c1\"># 3. gradient descent optimizer and loss function \n</span><span class=\"n\">sgd</span> <span class=\"o\">=</span> <span class=\"n\">optimizers</span><span class=\"p\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">compile</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s\">'mse'</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">sgd</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 4. Train the model \n</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</code></pre></div></div><p>Kết quả:</p><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Epoch 1/100\n100/100 [==============================] - 0s 5ms/step - loss: 1.7199\nEpoch 2/100\n100/100 [==============================] - 0s 709us/step - loss: 0.0388\nEpoch 3/100\n100/100 [==============================] - 0s 675us/step - loss: 0.0415\nEpoch 4/100\n100/100 [==============================] - 0s 774us/step - loss: 0.0392\nEpoch 5/100\n.....\nEpoch 100/100\n100/100 [==============================] - 0s 823us/step - loss: 0.0393\n</code></pre></div></div><p>Ta thấy răng thuật toán hội tụ khá nhanh và MSE loss khá nhỏ sau khi huấn luyện xong.</p><p>Chúng ta cùng xem xét từng bước:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 2. Build model \n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">([</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'linear'</span><span class=\"p\">)])</span>\n\n</code></pre></div></div><p><code class=\"language-plaintext highlighter-rouge\">Sequantial([&lt;a list&gt;])</code> là thể hiện việc các layer được xây dựng theo đúng thứ tự trong <code class=\"language-plaintext highlighter-rouge\">[&lt;a list&gt;]</code>. Phần tử đầu tiên của list thể hiện kết nối giưa input layer và layer tiếp theo, các phần tử tiếp theo của list thể hiện kết nối của các layer tiếp theo.</p><p><code class=\"language-plaintext highlighter-rouge\">Dense</code> thể hiện một <em>fully connected layer</em>, tức toàn bộ các unit của layer trước đó được nối với toàn bộ các unit của layer hiện tại. Giá trị đầu tiên trong <code class=\"language-plaintext highlighter-rouge\">Dense</code> bằng <code class=\"language-plaintext highlighter-rouge\">1</code> thể hiện việc chỉ có 1 unit ở layer này (đầu ra của linear regression trong trường hợp này bằng 1). <code class=\"language-plaintext highlighter-rouge\">input_shape = (2,)</code> chính là kích thước của dữ liệu đầu vào. Kích thước này là một tuple nên ta cần viết dưới dạng <code class=\"language-plaintext highlighter-rouge\">(2,)</code>. Về sau, khi làm việc với dữ liệu nhiều chiều, ta sẽ có các tuple nhiều chiều. Ví dụ, nếu input là ảnh RGB với kích thước 224x224x3 pixel thì <code class=\"language-plaintext highlighter-rouge\">input_shape = (224, 224, 3)</code>.</p><p>Các layer cũng có thể được thêm lần lượt vào <code class=\"language-plaintext highlighter-rouge\">model</code> bằng cách sử dụng hàm <code class=\"language-plaintext highlighter-rouge\">.add()</code>. Đoạn code phía trên và đoạn code ngay dưới đây là tương đương.</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'linear'</span><span class=\"p\">))</span>\n</code></pre></div></div><p>Activation cũng có thể được tách ra thành riêng một layer như sau:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 2. Build model \n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,)))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Activation</span><span class=\"p\">(</span><span class=\"s\">'linear'</span><span class=\"p\">))</span>\n</code></pre></div></div><p>Bạn đọc có thể đọc về các activation của Keras <a href=\"https://keras.io/activations/\">tại đây</a>.</p><p>Đoạn code tiếp theo:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 3. gradient descent optimizer and loss function \n</span><span class=\"n\">sgd</span> <span class=\"o\">=</span> <span class=\"n\">optimizers</span><span class=\"p\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">compile</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s\">'mse'</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">sgd</span><span class=\"p\">)</span>\n</code></pre></div></div><p>Thể hiện việc chọn phương pháp cập nhật nghiệm, ở đâu ta sử dụng <a href=\"https://machinelearningcoban.com/2017/01/16/gradientdescent2/#-stochastic-gradient-descent\">Stochastic Gradient Descent (SGD)</a> với learning rate <code class=\"language-plaintext highlighter-rouge\">lr=0.1</code>. Các phương pháp cập nhật nghiệm khác có thể được tìm thấy tại <a href=\"https://keras.io/optimizers/\">Keras-Usage of optimizers</a>.\n<code class=\"language-plaintext highlighter-rouge\">loss='mse'</code> chính là <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\"><em>mean squared error</em></a>, là hàm mất mát của linear regression.</p><p>Sau khi xây dựng được mô hình và chỉ ra phương pháp cập nhật cũng như hàm mất mát, ta huấn luyện mô hình bằng:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</code></pre></div></div><p>(Keras khá giống với scikit-learn ở chỗ cùng huấn luyện các mô hình bằng phương thức <code class=\"language-plaintext highlighter-rouge\">.fit()</code>). Ở đây, <code class=\"language-plaintext highlighter-rouge\">epochs</code> chính là số lượng <a href=\"https://machinelearningcoban.com/2017/01/16/gradientdescent2/#-stochastic-gradient-descent\">epoch</a> và <code class=\"language-plaintext highlighter-rouge\">batch_size</code> chính là kích thước của một <a href=\"https://0.0.7.225/01/16/gradientdescent2/#-mini-batch-gradient-descent\">mini-batch</a>.</p><p>Để xem hệ số tìm được của linear regression, ta sử dụng:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">get_weights</span><span class=\"p\">()</span>\n</code></pre></div></div><p>Kết quả:</p><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[array([[1.996118 ],\n        [3.0239758]], dtype=float32), array([3.963116], dtype=float32)]\n</code></pre></div></div><p>ở đó, phần tử thứ nhất của list này chính là hệ số tìm được, phẩn tử thứ hai chính là bias. Kết quả này gần với nghiệm mong đợi của bài toán (<code class=\"language-plaintext highlighter-rouge\">y = 2*X[0] + 3*X[1] + 4</code>).</p><p><em>Tương đối đơn giản.</em></p><p><a name=\"-keras-voi-logistic-regression\"></a></p><h3 id=\"21-keras-với-logistic-regression\">2.1. Keras với logistic regression</h3><p>Quay lại <a href=\"https://machinelearningcoban.com/2017/01/27/logisticregression/#-vi-du-voi-python\">ví dụ về mối liên hệ giữa số giờ ôn tập và kết quả thi trong bài logistic regression</a>, bài toán có thể được giải quyết bằng keras như sau:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span> \n<span class=\"kn\">from</span> <span class=\"nn\">keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Sequential</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.layers.core</span> <span class=\"kn\">import</span> <span class=\"n\">Dense</span><span class=\"p\">,</span> <span class=\"n\">Activation</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">losses</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">optimizers</span>\n\n<span class=\"c1\"># 1. Prepare data \n</span><span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">0.50</span><span class=\"p\">,</span> <span class=\"mf\">0.75</span><span class=\"p\">,</span> <span class=\"mf\">1.00</span><span class=\"p\">,</span> <span class=\"mf\">1.25</span><span class=\"p\">,</span> <span class=\"mf\">1.50</span><span class=\"p\">,</span> <span class=\"mf\">1.75</span><span class=\"p\">,</span> <span class=\"mf\">1.75</span><span class=\"p\">,</span> <span class=\"mf\">2.00</span><span class=\"p\">,</span> <span class=\"mf\">2.25</span><span class=\"p\">,</span> <span class=\"mf\">2.50</span><span class=\"p\">,</span> \n              <span class=\"mf\">2.75</span><span class=\"p\">,</span> <span class=\"mf\">3.00</span><span class=\"p\">,</span> <span class=\"mf\">3.25</span><span class=\"p\">,</span> <span class=\"mf\">3.50</span><span class=\"p\">,</span> <span class=\"mf\">4.00</span><span class=\"p\">,</span> <span class=\"mf\">4.25</span><span class=\"p\">,</span> <span class=\"mf\">4.50</span><span class=\"p\">,</span> <span class=\"mf\">4.75</span><span class=\"p\">,</span> <span class=\"mf\">5.00</span><span class=\"p\">,</span> <span class=\"mf\">5.50</span><span class=\"p\">])</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"p\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># 2. Build model \n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,)))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Activation</span><span class=\"p\">(</span><span class=\"s\">'sigmoid'</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># 3. gradient descent optimizer and loss function \n</span><span class=\"n\">sgd</span> <span class=\"o\">=</span> <span class=\"n\">optimizers</span><span class=\"p\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.05</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">compile</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">losses</span><span class=\"p\">.</span><span class=\"n\">binary_crossentropy</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">sgd</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 4. Train the model \n</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">3000</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span> \n</code></pre></div></div><p>Có hai sự khác biệt ở <code class=\"language-plaintext highlighter-rouge\">Activation</code> và <code class=\"language-plaintext highlighter-rouge\">loss</code> vì logistic regression sử dụng hàm activation là sigmoid, hàm mất mát là trường hợp đặc biệt của cross entropy với hai class.</p><p>Kết quả tìm được tương đối giống với kết quả tìm được trước đó với numpy.</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">get_weights</span><span class=\"p\">()</span>\n</code></pre></div></div><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[array([[1.5141923]], dtype=float32), array([-4.1248693], dtype=float32)]\n</code></pre></div></div><p>và ta có <code class=\"language-plaintext highlighter-rouge\">y ~ 1.51*x - 4.12</code>.</p><p><a name=\"-keras-cho-multi-layer-perceptron\"></a></p><p>Chúng ta cùng xây dựng một mạng MLP đơn giản với Keras để giải quyết một bài toán phân loại ảnh.\n<a name=\"-gioi-thieu-ve-fashion-mnist\"></a></p><h3 id=\"31-giới-thiệu-về-fashion-mnist\">3.1. Giới thiệu về Fashion-MNIST</h3><p>Cơ sở dữ liệu ảnh được dùng là <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST</a>.</p><p>Chúng ta đã quá quen với việc sử dụng <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a>. MNIST là cơ sở dữ liệu về chữ số viết tay, được sử dụng rất rộng rãi trong cồng đồng AI/ML. MNIST thường được thử đầu tiên khi có một thuật toán phân loại ảnh mới. Một số người nói “<em>If it doesn’t work on MNIST, it won’t work at all</em>”. Nhưng đồng thời, “<em>Well, if it does work on MNIST, it may still fail on others.</em>”</p><p>Fashion-MNIST được tạo ra gần đây với kích thước tương tự như MNIST nhưng các ảnh là các ảnh xám của trang phục với các nhãn: (0) T-shirt/top, (1) Trouser, (2) Pullover, (3) Dress, (4) Coat, (5) Sandal, (6) Shirt, (7) Sneaker, (8) Bag, (9) Ankle boot. Fashion-MNIST cũng có 10 class, 60000 ảnh cho training, 10000 ảnh cho test, mỗi ảnh có kích thước 28x28 pixel và là các ảnh xám với chỉ một channel. Dưới đây là một ví dụ về ảnh của class (2) Pullover.</p><hr/><div class=\"imgcap\">\n<div>\n<img src=\"./ex19_files/mlp1.png\" width=\"255\"/>\n</div>\n<div class=\"thecap\">Hình ảnh một mẫu dữ liệu đầu vào với kích thước 28x28, tương ứng với nhãn \"pullover\" - áo len chui đầu <br/> </div>\n</div><hr/><p>Tác giả của Fashion-MNIST cho rằng cần phải thay thế MNIST vì:</p><ul>\n<li>\n<p><strong>MNIST đã trở nên quá dễ</strong>. Rất nhiều thuật toán deep learning đã đạt được độ chính xác lên tới 99.7%, ngay cả KNN cũng đạt được trên 96%. Rất khó để đánh bại con số 99.7%, và nếu mô hình của bạn đạt được con số này, ta vẫn khó có thể kết luận ngay đó là một mô hình tốt.</p>\n</li>\n<li>\n<p><strong>MNIST được sử dụng quá nhiều</strong> đến mức nhàm chán.</p>\n</li>\n<li>\n<p><strong>MNIST không đại diện cho các bài toán computer vision hiện đại</strong>.</p>\n</li>\n</ul><p>Cơ sở dữ liệu Fashion-MNIST có thể được tải về thông qua <code class=\"language-plaintext highlighter-rouge\">keras.datasets</code></p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># 1. prepare data \n</span><span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"kn\">import</span> <span class=\"n\">print_function</span> \n<span class=\"kn\">from</span> <span class=\"nn\">keras.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">fashion_mnist</span>\n\n<span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">fashion_mnist</span><span class=\"p\">.</span><span class=\"n\">load_data</span><span class=\"p\">()</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'x_train shape:</span><span class=\"se\">\\t</span><span class=\"s\">'</span><span class=\"p\">,</span> <span class=\"n\">x_train</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'x_test shape:</span><span class=\"se\">\\t</span><span class=\"s\">'</span><span class=\"p\">,</span> <span class=\"n\">x_test</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'y_train shape:</span><span class=\"se\">\\t</span><span class=\"s\">'</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'y_test shape:</span><span class=\"se\">\\t</span><span class=\"s\">'</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n</code></pre></div></div><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>x_train shape:   (60000, 28, 28)\nx_test shape:    (10000, 28, 28)\ny_train shape:   (60000,)\ny_test shape:    (10000,)\n</code></pre></div></div><p>Ở đây, <code class=\"language-plaintext highlighter-rouge\">x_train, x_test</code> mang các giá trị nguyên từ 0 đến 255, <code class=\"language-plaintext highlighter-rouge\">y_train, y_test</code> chứa các số nguyên từ 0 đến 9 thể hiện class của <code class=\"language-plaintext highlighter-rouge\">x</code> tương ứng. Nếu sử dụng một neural network với <a href=\"https://machinelearningcoban.com/2017/02/17/softmax/\">softmax layer</a> ở cuối, ta cần chuẩn hoá dữ liệu đầu vào <code class=\"language-plaintext highlighter-rouge\">x_train, x_test</code> về đoạn [0, 1] và chuyển <code class=\"language-plaintext highlighter-rouge\">y_train, y_test</code> về dạng one-hot coding.</p><p>Việc này có thể được thực hiện như sau:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\"># data normalization\n</span><span class=\"n\">x_train</span> <span class=\"o\">=</span> <span class=\"n\">x_train</span><span class=\"o\">/</span><span class=\"mf\">255.</span>\n<span class=\"n\">x_test</span> <span class=\"o\">=</span> <span class=\"n\">x_test</span><span class=\"o\">/</span><span class=\"mf\">255.</span> \n<span class=\"n\">num_classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span> \n<span class=\"c1\"># convert class vectors to binary class matrices\n</span><span class=\"n\">y_train</span> <span class=\"o\">=</span> <span class=\"n\">keras</span><span class=\"p\">.</span><span class=\"n\">utils</span><span class=\"p\">.</span><span class=\"n\">to_categorical</span><span class=\"p\">(</span><span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">)</span>\n<span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">keras</span><span class=\"p\">.</span><span class=\"n\">utils</span><span class=\"p\">.</span><span class=\"n\">to_categorical</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">)</span>\n</code></pre></div></div><p><a name=\"-xay-dung-mot-multi-layer-perceptron-de-giai-quyet-bai-toan\"></a></p><h3 id=\"32-xây-dựng-một-multi-layer-perceptron-để-giải-quyết-bài-toán\">3.2. Xây dựng một multi-layer perceptron để giải quyết bài toán</h3><p>Ta đã thực hiện bước đầu tiên trong bài toán xây dựng mô hình neural network cho bài toán classification – bước chuẩn bị dữ liệu.</p><p>Trong mục này, chúng ta sẽ đi xây dựng một neural network đơn giản. Một mô hình đủ đơn giản giúp chúng ta tiếp tục làm quen với Keras là <a href=\"https://machinelearningcoban.com/2017/02/24/mlp/\">multi-layer perceptron</a>.</p><p>Ta sẽ xây dựng một MLP với 3 hidden layers. Các layer cụ thể như sau:</p><ol>\n<li>Input layer với số units là <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"mjx-chtml MathJax_CHTML\" data-mathml='&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"&gt;&lt;mn&gt;28&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;28&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;784&lt;/mn&gt;&lt;/math&gt;' id=\"MathJax-Element-1-Frame\" role=\"presentation\" style=\"font-size: 117%; position: relative;\" tabindex=\"0\"><span aria-hidden=\"true\" class=\"mjx-math\" id=\"MJXc-Node-1\"><span class=\"mjx-mrow\" id=\"MJXc-Node-2\"><span class=\"mjx-mn\" id=\"MJXc-Node-3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.377em; padding-bottom: 0.377em;\">28</span></span><span class=\"mjx-mo MJXc-space2\" id=\"MJXc-Node-4\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.216em; padding-bottom: 0.323em;\">×</span></span><span class=\"mjx-mn MJXc-space2\" id=\"MJXc-Node-5\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.377em; padding-bottom: 0.377em;\">28</span></span><span class=\"mjx-mo MJXc-space3\" id=\"MJXc-Node-6\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.056em; padding-bottom: 0.323em;\">=</span></span><span class=\"mjx-mn MJXc-space3\" id=\"MJXc-Node-7\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.377em; padding-bottom: 0.377em;\">784</span></span></span></span><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>28</mn><mo>×</mo><mn>28</mn><mo>=</mo><mn>784</mn></math></span></span><script id=\"MathJax-Element-1\" type=\"math/tex\">28\\times 28 = 784</script>. Mỗi input là một bức ảnh của Fashion-MNIST được <em>kéo dài ra</em> thành một vector.</li>\n<li>Hidden layer thứ nhất với 128 units, activation là ReLU.</li>\n<li>Hidden layer thứ hai với 256 units, activation là ReLU.</li>\n<li>Hidden layer thứ ba với 512 units, activation là ReLU.</li>\n<li>Output layer là một softmax layer với 10 units.</li>\n</ol><p>Hàm mất mát là cross entropy, ta tạm thời chưa quan tâm đến <a href=\"https://machinelearningcoban.com/2017/03/04/overfitting/#-regularization\">regularization</a> (ở đây là <a href=\"https://machinelearningcoban.com/2017/03/04/overfitting/#-%5C%5Cl%5C%5C-regularization\">weight decay</a>).</p><p>Phương pháp đánh giá hệ thống phân lớp này là <code class=\"language-plaintext highlighter-rouge\">'accuracy'</code>, tức số lượng điểm được phân loại đúng trong toàn bộ số điểm.</p><p>Network đơn giản này được thực hiện trên Keras như sau:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">keras.layers</span> <span class=\"kn\">import</span> <span class=\"n\">Dense</span><span class=\"p\">,</span> <span class=\"n\">Flatten</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Sequential</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">metrics</span> \n<span class=\"c1\"># 2. buid model \n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Flatten</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">)))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'relu'</span><span class=\"p\">))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'relu'</span><span class=\"p\">))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'relu'</span><span class=\"p\">))</span>\n<span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">num_classes</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s\">'softmax'</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># 3. loss, metrics \n</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"nb\">compile</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">keras</span><span class=\"p\">.</span><span class=\"n\">losses</span><span class=\"p\">.</span><span class=\"n\">categorical_crossentropy</span><span class=\"p\">,</span>\n              <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">keras</span><span class=\"p\">.</span><span class=\"n\">optimizers</span><span class=\"p\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">),</span>\n              <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s\">'accuracy'</span><span class=\"p\">])</span>\n</code></pre></div></div><p>Ở đây có một hàm mới là <code class=\"language-plaintext highlighter-rouge\">Flatten()</code>, hàm này biến mỗi điểm dữ liểu ở dạng một mảng nhiều chiều thành một mảng một chiều. <em>Vì ta đang sử dụng MLP nên ta cần làm công việc này. Về sau, khi sử dụng CNN, việc giữ nguyên mảng hai chiều sẽ cho kết quả tốt hơn.</em></p><p>Kết quả sau khi thực hiện đoạn code trên</p><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Epoch 1/20\n60000/60000 [==============================] - 3s 47us/step - loss: 0.6784 - acc: 0.7582\n....\nEpoch 20/20\n60000/60000 [==============================] - 3s 54us/step - loss: 0.2140 - acc: 0.9192\n</code></pre></div></div><p>Sau 20 epochs, mô hình cho độ chính xác trên tập huấn luyện <code class=\"language-plaintext highlighter-rouge\">x_train</code> khá cao.</p><p>Nếu chúng ta muốn đánh giá mô hình trên tập <code class=\"language-plaintext highlighter-rouge\">x_test</code>, ta có thể thực hiện như sau:</p><div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">keras</span> <span class=\"kn\">import</span> <span class=\"n\">metrics</span> \n<span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'Test loss: %.4f'</span><span class=\"o\">%</span> <span class=\"n\">score</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'Test accuracy %.4f'</span><span class=\"o\">%</span> <span class=\"n\">score</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n</code></pre></div></div><div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Test loss: 0.3312\nTest accuracy 0.8840\n</code></pre></div></div><p>Như vậy, độ chính xác của mô hình trên tập kiểm thử đạt 88.4%.</p><p><em>Bạn đọc có thể thử giải quyết bài toán này bằng các thuật toán phân loại khác và so sánh kết quả.</em></p><p><a name=\"-nhan-xet\"></a></p><h3 id=\"33-nhận-xét\">3.3. Nhận xét</h3><ul>\n<li>\n<p>Dữ liệu đầu vào chỉ là 784 chiều và đặc trưng cho dữ liệu thời trang cũng không quá phức tạp trên nền là một màu đen và ảnh đã được căn chỉnh đúng tâm, đúng kích thước. MLP mặc dù cho kết quả tương đối tốt trong bài toán này, nó không phải là một mô hình tối ưu cho dữ liệu dạng ảnh vì ít nhất, dữ liệu ảnh hai chiều ban đầu đã được <em>dàn phẳng</em> ra thành dữ liệu một chiều, làm mất đi những thông tin về không gian trong ảnh (spatial information). Convolutional neural network thông thường sẽ cho kết quả tốt hơn. Tôi sẽ sớm giới thiệu với bạn đọc về kiến trúc này.</p>\n</li>\n<li>\n<p>Mạng MLP đơn giản này chưa dùng nhiều kỹ thuật của deep learning, chúng ta sẽ dần làm quen với các kỹ thuật giúp tăng độ chính xác và giảm thời gian huấn luyện trong các bài sau.</p>\n</li>\n</ul><p><a name=\"-ket-luan\"></a></p>"}, "examples": {"title": "<h2 id=\"4-kết-luận\">4. Kết luận</h2>", "content": "<ul>\n<li>\n<p>Keras là một thư viện tương đối dễ sử dụng đối với người mới bắt đầu. Nó cung cấp các hàm số cần thiết với cú pháp đơn giản.</p>\n</li>\n<li>\n<p>Khi đi sâu hơn vào deep learning trong các bài sau, chúng ta sẽ dần làm quen với các kỹ thuật lập trình với Keras. Mời các bạn đón đọc.</p>\n</li>\n<li>\n<p>Source code trong bài này có thể được tìm thấy <a href=\"https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/36_keras/Keras.ipynb\">tại đây</a>.\n<a name=\"-tai-lieu-tham-khao\"></a></p>\n</li>\n</ul>"}}