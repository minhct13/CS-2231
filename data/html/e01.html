<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="utf-8" />
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>Machine Learning cơ bản</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300" rel="stylesheet">
  <!-- <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> -->
  <link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans" rel="stylesheet">

<!-- Include CSS SCSS -->

   <link rel="stylesheet" type="text/css" href="/style/post.css" />
   <link rel="stylesheet" type="text/css" href="/css/monokai.css" />
   <link rel="stylesheet" type="text/css" href="/css/mystyle.css" />
   <!-- <link rel="stylesheet" type="text/css" href="/css/github.css" /> -->


<title>Bài 3: Linear Regression</title>
<!-- <script>
var pageProperties = {
    
    category: "Regression",
    
    url: "/2016/12/28/linearregression/",
    title: "Bài 3: Linear Regression",
    scripts: [
        
    ],
};

</script>
<script src="/scripts/modules.js" async></script>
 -->

<link rel="icon" type="image/png" href="https://raw.githubusercontent.com/tiepvupsu/tiepvupsu.github.io/master/assets/latex/new_logo9.png" sizes="32x32">
<link rel="canonical" href="https://machinelearningcoban.com/2016/12/28/linearregression/"/>
<meta name="author" content="Tiep Vu " />


   <meta property="og:title" content="Bài 3: Linear Regression" />
   <meta property="og:site_name" content="Tiep Vu's blog" />
   <meta property="og:url" content="https://machinelearningcoban.com/2016/12/28/linearregression/" />
   <meta property="og:description" content="" />
   
   <meta property="og:type" content="article" />
   <meta property="article:published_time" content="2016-12-28" />
   

   <meta property="article:author" content="Tiep Vu" />
   <meta property="article:section" content="Regression" />
   
      <meta property="article:tag" content="Linear-models" />
   
      <meta property="article:tag" content="Regression" />
   
      <meta property="article:tag" content="Supervised-learning" />
   


<link rel="alternate" type="application/atom+xml" title="Tiep Vu's blog - Atom feed" href="/feed.xml" />



<!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-89509207-1', 'auto');
// ga('send', 'pageview');
ga('send', 'pageview', {
'page': '/2016/12/28/linearregression/',
'title': 'Bài 3: Linear Regression'
});
</script>


<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KTCD8BX');</script>
<!-- End Google Tag Manager -->
</head>

<body>
	<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
    <br>
    <div class="container">
      	<div class="row">
	        <div class="col-md-2 hidden-xs hidden-sm">
	          	<a   href="/">
            <!-- <img width="80%" src="/images/logo.svg" /> -->
            <!-- <img width="100%" src="/images/logoTet.png" /> -->
            <!-- <img width="100%" src="/images/logo2.png" /> -->
            <!-- <img width="100%" style="padding-bottom: 3mm;" src="/images/logo_new.png" /> </a> -->
            <img width="100%" style="padding-bottom: 3mm;" src="/assets/latex/new_logo92.png" /> </a>
          <!-- <img width="100%" style="padding-bottom: 3mm;" src="/assets/latex/new_logo2_rau.png" /> </a> -->

            <br>
            <a href = "/buymeacoffee">
            <img width="100%" style="padding-bottom: 3mm;" src="/images/Buymeacoffee_blue.png" />

            <br>
            <a href = "/ebook">
            <img width="100%" style="padding-bottom: 3mm;" src="/images/ebook_logo.png" />


            <!-- <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#074B80', 
            'A40822MV');kofiwidget2.draw();</script>  --><!-- 
            <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
            <input type="hidden" name="cmd" value="_donations">
            <input type="hidden" name="business" value="vuhuutiep@gmail.com">
            <input type="hidden" name="lc" value="US">
            <input type="hidden" name="item_name" value="I find machinelearningcoban.com helpful. I'd like to buy Tiep Vu a coffee ^^. (Thank you so much for your support.)">
            <input type="hidden" name="no_note" value="0">
            <input type="hidden" name="currency_code" value="USD">
            <input type="hidden" name="bn" value="PP-DonationsBF:Buymeacoffee.png:NonHostedGuest">
            <input type="image" src="/images/Buymeacoffee_blue.png" border="0" style="padding-bottom: -9mm;" width = 100% name="submit" alt="PayPal - The safer, easier way to pay online!">
            </form> -->

            <!-- <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#805007', 'A40822MV');kofiwidget2.draw();</script>  -->

          </a>

          <!-- Google search -->
         <!--  <table border="0">
          <div id = "top-widget" style="width: 292px; margin-left: -13.5px; margin-top: -10px; margin-bottom: -15px;">
         <script>
           (function() {
             var cx = '012053542614118746585:ktgei4l2oek';
             var gcse = document.createElement('script');
             gcse.type = 'text/javascript';
             gcse.async = true;
             gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
             var s = document.getElementsByTagName('script')[0];
             s.parentNode.insertBefore(gcse, s);
           })();
         </script>
         <gcse:search></gcse:search>
          </div>
          </table> -->

          <!-- <nav>
          
            <div class="header">Popular</div>
            <ul>
              <li> (**): > 10k views</li>
              <li> (*) : > 5k views</li>
            </ul>
          </nav> -->
          

          
          <nav>
          
            <div class="header">Latest by category</div>
            <ul>
              
                
              
                
                  
                    <li><a style="text-align: left; color: #074B80;" href="/2016/12/28/linearregression/">3. Linear Regression</a></li>
                  
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
            </ul>
          </nav>
          



          <nav>
            <div class="header">Latest</div>
              
                <li><a style="text-align: left; color: #074B80"  href="/lifesofar2/">Con đường học PhD của tôi</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/10/03/conv2d">37. Tích chập hai chiều</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/09/11/forum/">Diễn đàn</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/07/06/deeplearning/">36. Keras</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/06/22/deeplearning/">35. Lược sử Deep Learning</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/03/22/phuonghoagiang/">Con đường học Khoa học dữ liệu của một sinh viên Kinh tế</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2018/01/14/id3/">34. Decision Trees (1): ID3</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/08/31/evaluation/">33. Đánh giá hệ thống phân lớp</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/10/20/fundaml_vectors/">FundaML 3: Các mảng ngẫu nhiên</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/10/20/fundaml_matrices/">FundaML 2: Ma trận</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/10/12/fundaml_vectors/">FundaML 1: Mảng một chiều</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/09/24/fundaml/">FundaML.com</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/08/08/nbc/">32. Naive Bayes Classifier</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/08/05/phdlife/">Viết và nhận xét các bài báo khoa học</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/07/17/mlemap/">31. Maximum Likelihood và Maximum A Posteriori</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/lifesofar/">Con đường học Toán của tôi</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/07/09/prob/">30. Ôn tập Xác Suất</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/07/02/tl/">Q2. Transfer Learning</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/06/30/lda/">29. Linear Discriminant Analysis</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/06/22/qns1/">Q1. Quick Notes 1</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/06/21/pca2/">28. Principal Component Analysis (2/2)</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/06/15/pca/">27. Principal Component Analysis (1/2)</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/06/07/svd/">26. Singular Value Decomposition</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/05/31/matrixfactorization/">25. Matrix Factorization Collaborative Filtering</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/05/24/collaborativefiltering/">24. Neighborhood-Based Collaborative Filtering</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/05/17/contentbasedrecommendersys/">23. Content-based Recommendation Systems</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/04/28/multiclasssmv/">22. Multi-class SVM</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/04/22/kernelsmv/">21. Kernel SVM</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/04/13/softmarginsmv/">20. Soft Margin SVM</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/04/09/smv/">19. Support Vector Machine</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/04/02/duality/">18. Duality</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/03/19/convexopt/">17. Convex Optimization Problems</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/03/12/convexity/">16. Convex sets và convex functions</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/03/04/overfitting/">15. Overfitting</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/02/24/mlp/">14. Multi-layer Perceptron và Backpropagation</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/02/17/softmax/">13. Softmax Regression</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/02/11/binaryclassifiers/">12. Binary Classifiers</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/general/2017/02/06/featureengineering/">11. Feature Engineering</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/02/02/howdoIcreatethisblog/"></a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/27/logisticregression/">10. Logistic Regression</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/21/perceptron/">9. Perceptron Learning Algorithm</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/16/gradientdescent2/">8. Gradient Descent (2/2)</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/12/gradientdescent/">7. Gradient Descent (1/2)</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/08/knn/">6. K-nearest neighbors</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/04/kmeans2/">5. K-means Clustering - Applications</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2017/01/01/kmeans/">4. K-means Clustering</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2016/12/28/linearregression/">3. Linear Regression</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2016/12/27/categories/">2. Phân nhóm các thuật toán Machine Learning</a></li>
              
                <li><a style="text-align: left; color: #074B80"  href="/2016/12/26/introduce/">1. Giới thiệu về Machine Learning</a></li>
              
            </ul>
          </nav>

          
          
          <!-- <img style = "transform: scaleX(1); width:100%; margin-left:00px;position: absolute;" src = "/images/mai.jpg"> -->
         
         <!--   
            <nav>
              <div class="header">Previous by date</div>
              <ul>
                <li><a style="text-align: left; font-family: 'Roboto Condensed', sans-serif; color: #074B80;" href="/2016/12/27/categories/">Bài 2: Phân nhóm các thuật toán Machine Learning</a></li>
              </ul>
            </nav>
           
           
            <nav>
              <div class="header">Next by date</div>
              <ul>
                <li><a style="text-align: left; font-family: 'Roboto Condensed', sans-serif; color: #074B80;" href="/2017/01/01/kmeans/">Bài 4: K-means Clustering</a></li>
              </ul>
            </nav>
            -->
		       
	        </div>
	        <div class="col-md-8 col-xs-12" style = "z-index: 1">
	        	 <!-- <br> -->
 <nav class="navbar navbar-inverse" style="background-color: #074B80">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span> 
      </button>
      <a class="navbar-brand" href="/"><span style = "color: #fff">Machine Learning cơ bản</span></a>
        <!-- <form class="navbar-form navbar-left" role="search">
            <div class="form-group" align="right">
                <input type="text" class="form-control" placeholder="Search">
            </div>
            <button type="submit" class="btn btn-default">
                <span></span>
            </button>
        </form> -->
        


    </div>
    <div class="collapse navbar-collapse navbar-right" id="myNavbar">
      <ul class="nav navbar-nav">
        <li><a href="/about/" ><span style = "color: #fff"> About</span></a></li>
        <li><a href="/index/"><span style = "color: #fff">Index</span></a></li>
        <li><a href="/tags/"><span style = "color: #fff">Tags</span></a></li>
        <li><a href="/categories/"><span style = "color: #fff">Categories</span></a></li>
        <li><a href="/archive/"><span style = "color: #fff">Archive</span></a></li>
        <li><a href="/math/"><span style = "color: #fff">Math</span></a></li>
        <!-- <li><a href="https://docs.google.com/forms/d/e/1FAIpQLScq3GkxM1I2fDevR7gth-O9QqxM7grf4AFc0WT1hFORv4flaw/viewform"><span style = "color: #fff">Survey</span></a></li> -->
        <li><a href="/copyrights/"><span style = "color: #fff">Copyrights</span></a></li>
        <!-- <li><a href="/faqs/"><span style = "color: #fff">FAQs</span></a></li> -->
        <li><a href="/ebook/"><span style = "color: #fff">ebook</span></a></li>
        <li><a href="/search/"><span style = "color: #fff">Search</span></a></li>
        <!-- <li><a href="https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/latex/book.pdf"><span style = "color: #fff">Book</span></a></li> -->
        <!-- <li><a href="https://www.facebook.com/groups/257768141347267/"><span style = "color: #fff">Forum</span></a></li> -->
        <!-- <li><a href="/subscribe/">Subscribe</a></li> -->

        <li> 
      </ul>
    </div>
  </div>
</nav>

	            <!-- <div class = "row"> -->
   <!-- <div class = "col-xs-12 hidden-md hidden-lg"> -->
      <!-- previous and next posts -->
      <div class="PageNavigation">
         
            <a class="prev" style = "color: #074B80;" href="/2016/12/27/categories/">&laquo; Bài 2: Phân nhóm các thuật toán Machine Learning</a>
         <!-- <hr> -->
         
         
            <a class="next" style = "float: right; color: #074B80;" href="/2017/01/01/kmeans/">Bài 4: K-means Clustering &raquo;</a>
         <hr>
         
      </div>
  <!-- </div> -->
<!-- </div> -->
<h1 itemprop="name" class="post-title">Bài 3: Linear Regression</h1>


<ul class = "tags">
   
      <a href="/tags#Linear-models" class="tag">Linear-models</a>
   
      <a href="/tags#Regression" class="tag">Regression</a>
   
      <a href="/tags#Supervised-learning" class="tag">Supervised-learning</a>
   
</ul>



<span class = "post-date" style="color: gray; font-style: italic;">Dec 28, 2016
            </span>
<!-- Main content -->
<br>
<br>



<div itemprop="articleBody">
   <p>Trong bài này, tôi sẽ giới thiệu một trong những thuật toán cơ bản nhất (và đơn giản nhất) của Machine Learning. Đây là một thuật toán <em>Supervised learning</em> có tên <strong>Linear Regression</strong> (Hồi Quy Tuyến Tính). Bài toán này đôi khi được gọi là <em>Linear Fitting</em> (trong thống kê) hoặc <em>Linear Least Square</em>.
<strong>Trong trang này:</strong>
<!-- MarkdownTOC --></p>

<ul>
  <li><a href="#-gioi-thieu">1. Giới thiệu</a></li>
  <li><a href="#-phan-tich-toan-hoc">2. Phân tích toán học</a>
    <ul>
      <li><a href="#-dang-cua-linear-regression">2.1. Dạng của Linear Regression</a></li>
      <li><a href="#-sai-so-du-doan">2.2. Sai số dự đoán</a></li>
      <li><a href="#-ham-mat-mat">2.3. Hàm mất mát</a></li>
      <li><a href="#-nghiem-cho-bai-toan-linear-regression">2.4. Nghiệm cho bài toán Linear Regression</a></li>
    </ul>
  </li>
  <li><a href="#-vi-du-tren-python">3. Ví dụ trên Python</a>
    <ul>
      <li><a href="#-bai-toan">3.1. Bài toán</a></li>
      <li><a href="#-hien-thi-du-lieu-tren-do-thi">3.2. Hiển thị dữ liệu trên đồ thị</a></li>
      <li><a href="#-nghiem-theo-cong-thuc">3.3. Nghiệm theo công thức</a></li>
      <li><a href="#-nghiem-theo-thu-vien-scikit-learn">3.4. Nghiệm theo thư viện scikit-learn</a></li>
    </ul>
  </li>
  <li><a href="#-thao-luan">4. Thảo luận</a>
    <ul>
      <li><a href="#-cac-bai-toan-co-the-giai-bang-linear-regression">4.1. Các bài toán có thể giải bằng Linear Regression</a></li>
      <li><a href="#-han-che-cua-linear-regression">4.2. Hạn chế của Linear Regression</a></li>
      <li><a href="#-cac-phuong-phap-toi-uu">4.3. Các phương pháp tối ưu</a></li>
    </ul>
  </li>
  <li><a href="#-tai-lieu-tham-khao">5. Tài liệu tham khảo</a></li>
</ul>

<!-- /MarkdownTOC -->

<!-- ========================== New Heading ==================== -->
<p><a name="-gioi-thieu"></a></p>

<h2 id="1-giới-thiệu">1. Giới thiệu</h2>

<p>Quay lại <a href="/2016/12/27/categories/#regression-hoi-quy">ví dụ đơn giản được nêu trong bài trước</a>: một căn nhà rộng \(x_1 ~ \text{m}^2\), có \(x_2\) phòng ngủ và cách trung tâm thành phố \(x_3~ \text{km}\) có giá là bao nhiêu. Giả sử chúng ta đã có số liệu thống kê từ 1000 căn nhà trong thành phố đó, liệu rằng khi có một căn nhà mới với các thông số về diện tích, số phòng ngủ và khoảng cách tới trung tâm, chúng ta có thể dự đoán được giá của căn nhà đó không? Nếu có thì hàm dự đoán \(y = f(\mathbf{x}) \) sẽ có dạng như thế nào. Ở đây \(\mathbf{x} = [x_1, x_2, x_3] \) là một vector hàng chứa thông tin <em>input</em>, \(y\) là một số vô hướng (scalar) biểu diễn <em>output</em> (tức giá của căn nhà trong ví dụ này).</p>

<p><strong>Lưu ý về ký hiệu toán học:</strong> <em>trong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \(x_1, N, y, k\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \(\mathbf{y}, \mathbf{x}_1 \). Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \(\mathbf{X, Y, W} \).</em></p>

<p>Một cách đơn giản nhất, chúng ta có thể thấy rằng: i) diện tích nhà càng lớn thì giá nhà càng cao; ii) số lượng phòng ngủ càng lớn thì giá nhà càng cao; iii) càng xa trung tâm thì giá nhà càng giảm. Một hàm số đơn giản nhất có thể mô tả mối quan hệ giữa giá nhà và 3 đại lượng đầu vào là:</p>

<!-- \\[ \text{ giá nhà } \approx w_1 (\text{diện tích}) + w_2 (\text{số phòng}) + w_3 (\text{ khoảng cách}) + w_0 \\]  -->

<p>\[y \approx  f(\mathbf{x}) = \hat{y}\]
\[f(\mathbf{x}) =w_1 x_1 + w_2 x_2 + w_3 x_3 + w_0 ~~~~ (1)\]
trong đó, \(w_1, w_2, w_3, w_0\) là các hằng số,  \(w_0\) còn được gọi là bias. Mối quan hệ \(y \approx f(\mathbf{x})\) bên trên là một mối quan hệ tuyến tính (linear). Bài toán chúng ta đang làm là một bài toán thuộc loại regression. Bài toán đi tìm các hệ số tối ưu \( \{w_1, w_2, w_3, w_0 \}\) chính vì vậy được gọi là bài toán Linear Regression.</p>

<p><strong>Chú ý 1:</strong> \(y\) là giá trị thực của <em>outcome</em> (dựa trên số liệu thống kê chúng ta có trong tập <em>training data</em>), trong khi \(\hat{y}\) là giá trị mà mô hình Linear Regression dự đoán được. Nhìn chung, \(y\) và \(\hat{y}\) là hai giá trị khác nhau do có sai số mô hình, tuy nhiên, chúng ta mong muốn rằng sự khác nhau này rất nhỏ.</p>

<p><strong>Chú ý 2:</strong> <em>Linear</em> hay <em>tuyến tính</em> hiểu một cách đơn giản là <em>thẳng, phẳng</em>. Trong không gian hai chiều, một hàm số được gọi là <em>tuyến tính</em> nếu đồ thị của nó có dạng một <em>đường thẳng</em>. Trong không gian ba chiều, một hàm số được goi là <em>tuyến tính</em> nếu đồ thị của nó có dạng một <em>mặt phẳng</em>. Trong không gian nhiều hơn 3 chiều, khái niệm <em>mặt phẳng</em> không còn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi là <em>siêu mặt phẳng</em> (<em>hyperplane</em>). Các hàm số tuyến tính là các hàm đơn giản nhất, vì chúng thuận tiện trong việc hình dung và tính toán. Chúng ta sẽ được thấy trong các bài viết sau, <em>tuyến tính</em> rất quan trọng và hữu ích trong các bài toán Machine Learning. Kinh nghiệm cá nhân tôi cho thấy, trước khi hiểu được các thuật toán <em>phi tuyến</em> (non-linear, không phẳng), chúng ta cần nắm vững các kỹ thuật cho các mô hình <em>tuyến tính</em>.</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-phan-tich-toan-hoc"></a></p>

<h2 id="2-phân-tích-toán-học">2. Phân tích toán học</h2>

<!-- ========================== New Heading ==================== -->
<p><a name="-dang-cua-linear-regression"></a></p>

<h3 id="21-dạng-của-linear-regression">2.1. Dạng của Linear Regression</h3>

<p>Trong phương trình \((1)\) phía trên, nếu chúng ta đặt \(\mathbf{w} = [w_0, w_1, w_2, w_3]^T = \) là vector (cột) hệ số cần phải tối ưu và \(\mathbf{\bar{x}} = [1, x_1, x_2, x_3]\) (đọc là <em>x bar</em> trong tiếng Anh) là vector (hàng) dữ liệu đầu vào <em>mở rộng</em>. Số \(1\) ở đầu được thêm vào để phép tính đơn giản hơn và thuận tiện cho việc tính toán. Khi đó, phương trình (1) có thể được viết lại dưới dạng:</p>

<p>\[y \approx \mathbf{\bar{x}}\mathbf{w} = \hat{y}\]</p>

<p>Chú ý rằng \(\mathbf{\bar{x}}\) là một vector hàng. (<a href="/math/#luu-y-ve-ky-hieu">Xem thêm về ký hiệu vector hàng và cột tại đây</a>)</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-sai-so-du-doan"></a></p>

<h3 id="22-sai-số-dự-đoán">2.2. Sai số dự đoán</h3>

<p>Chúng ta mong muốn rằng sự sai khác \(e\) giữa giá trị thực \(y\) và giá trị dự đoán \(\hat{y}\) (đọc là <em>y hat</em> trong tiếng Anh) là nhỏ nhất. Nói cách khác, chúng ta muốn giá trị sau đây càng nhỏ càng tốt:</p>

<p>\[
\frac{1}{2}e^2 = \frac{1}{2}(y - \hat{y})^2 = \frac{1}{2}(y - \mathbf{\bar{x}}\mathbf{w})^2
\]</p>

<p>trong đó hệ số \(\frac{1}{2} \) (<em>lại</em>) là để thuận tiện cho việc tính toán (khi tính đạo hàm thì số \(\frac{1}{2} \) sẽ bị triệt tiêu). Chúng ta cần \(e^2\) vì \(e = y - \hat{y} \) có thể là một số âm, việc nói \(e\) nhỏ nhất sẽ không đúng vì khi \(e = - \infty\) là rất nhỏ nhưng sự sai lệch là rất lớn. Bạn đọc có thể tự đặt câu hỏi: <strong>tại sao không dùng trị tuyệt đối \( |e| \) mà lại dùng bình phương \(e^2\) ở đây?</strong> Câu trả lời sẽ có ở phần sau.</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-ham-mat-mat"></a></p>

<h3 id="23-hàm-mất-mát">2.3. Hàm mất mát</h3>

<p>Điều tương tự xảy ra với tất cả các cặp <em>(input, outcome)</em> \( (\mathbf{x}_i, y_i), i = 1, 2, \dots, N \), với \(N\) là số lượng dữ liệu quan sát được. Điều chúng ta muốn, tổng sai số là nhỏ nhất, tương đương với việc tìm \( \mathbf{w} \) để hàm số sau đạt giá trị nhỏ nhất:</p>

<p>\[ \mathcal{L}(\mathbf{w}) = \frac{1}{2}\sum_{i=1}^N (y_i - \mathbf{\bar{x}_i}\mathbf{w})^2 ~~~~~(2) \]</p>

<p>Hàm số \(\mathcal{L}(\mathbf{w}) \) được gọi là <strong>hàm mất mát</strong> (loss function) của bài toán Linear Regression. Chúng ta luôn mong muốn rằng sự mất mát (sai số) là nhỏ nhất, điều đó đồng nghĩa với việc  tìm vector hệ số \( \mathbf{w} \)  sao cho 
giá trị của hàm mất mát này càng nhỏ càng tốt. Giá trị của \(\mathbf{w}\) làm cho hàm mất mát đạt giá trị nhỏ nhất được gọi là <em>điểm tối ưu</em> (optimal point), ký hiệu:</p>

<p>\[ \mathbf{w}^* = \arg\min_{\mathbf{w}} \mathcal{L}(\mathbf{w})  \]</p>

<p>Trước khi đi tìm lời giải, chúng ta đơn giản hóa phép toán trong phương trình hàm mất mát \((2)\). Đặt \(\mathbf{y} = [y_1; y_2; \dots; y_N]\) là một vector cột chứa tất cả các <em>output</em> của <em>training data</em>; \( \mathbf{\bar{X}} = [\mathbf{\bar{x}}_1; \mathbf{\bar{x}}_2; \dots; \mathbf{\bar{x}}_N ] \) là ma trận dữ liệu đầu vào (mở rộng) mà mỗi hàng của nó là một điểm dữ liệu. Khi đó hàm số mất mát \(\mathcal{L}(\mathbf{w})\) được viết dưới dạng ma trận đơn giản hơn:</p>

<p>\[
\mathcal{L}(\mathbf{w}) 
= \frac{1}{2}\sum_{i=1}^N (y_i - \mathbf{\bar{x}}_i\mathbf{w})^2 \]
\[
= \frac{1}{2} \|\mathbf{y} - \mathbf{\bar{X}}\mathbf{w} \|_2^2 ~~~(3) \]</p>

<p>với \( \| \mathbf{z} \|_2 \) là Euclidean norm (chuẩn Euclid, hay khoảng cách Euclid), nói cách khác \( \| \mathbf{z} \|_2^2 \) là tổng của bình phương mỗi phần tử của vector \(\mathbf{z}\). Tới đây, ta đã có một dạng đơn giản của hàm mất mát được viết như phương trình \((3)\).</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-nghiem-cho-bai-toan-linear-regression"></a></p>

<h3 id="24-nghiệm-cho-bài-toán-linear-regression">2.4. Nghiệm cho bài toán Linear Regression</h3>

<p><strong>Cách phổ biến nhất để tìm nghiệm cho một bài toán tối ưu (chúng ta đã biết từ khi học cấp 3) là giải phương trình đạo hàm (gradient) bằng 0!</strong> Tất nhiên đó là khi việc tính đạo hàm và việc giải phương trình đạo hàm bằng 0 không quá phức tạp. Thật may mắn, với các mô hình tuyến tính, hai việc này là khả thi.</p>

<p>Đạo hàm theo \(\mathbf{w} \) của hàm mất mát là: 
\[
\frac{\partial{\mathcal{L}(\mathbf{w})}}{\partial{\mathbf{w}}} 
= \mathbf{\bar{X}}^T(\mathbf{\bar{X}}\mathbf{w} - \mathbf{y}) 
\]</p>

<p>Các bạn có thể tham khảo bảng đạo hàm theo vector hoặc ma trận của một hàm số trong <a href="https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf">mục D.2 của tài liệu này</a>. <em>Đến đây tôi xin quay lại câu hỏi ở phần <a href="#sai so du doan">Sai số dự đoán</a> phía trên về việc tại sao không dùng trị tuyệt đối mà lại dùng bình phương. Câu trả lời là hàm bình phương có đạo hàm tại mọi nơi, trong khi hàm trị tuyệt đối thì không (đạo hàm không xác định tại 0)</em>.</p>

<p>Phương trình đạo hàm bằng 0 tương đương với: 
\[
\mathbf{\bar{X}}^T\mathbf{\bar{X}}\mathbf{w} = \mathbf{\bar{X}}^T\mathbf{y} \triangleq \mathbf{b}
~~~ (4)
\]
(ký hiệu \(\mathbf{\bar{X}}^T\mathbf{y} \triangleq \mathbf{b} \) nghĩa là <em>đặt</em> \(\mathbf{\bar{X}}^T\mathbf{y}\) <em>bằng</em> \(\mathbf{b}\) ).</p>

<p>Nếu ma trận vuông \( \mathbf{A} \triangleq \mathbf{\bar{X}}^T\mathbf{\bar{X}}\) khả nghịch (non-singular hay invertible) thì phương trình \((4)\) có nghiệm duy nhất: \( \mathbf{w} = \mathbf{A}^{-1}\mathbf{b}  \).</p>

<p>Vậy nếu ma trận \(\mathbf{A} \) không khả nghịch (có định thức bằng 0) thì sao? Nếu các bạn vẫn nhớ các kiến thức về hệ phương trình tuyến tính, trong trường hợp này thì hoặc phương trinh \( (4) \) vô nghiệm, hoặc là nó có vô số nghiệm. Khi đó, chúng ta sử dụng khái niệm <a href="https://vi.wikipedia.org/wiki/Giả_nghịch_đảo_Moore–Penrose"><em>giả nghịch đảo</em></a> \( \mathbf{A}^{\dagger} \) (đọc là <em>A dagger</em> trong tiếng Anh). (<em>Giả nghịch đảo (pseudo inverse) là trường hợp tổng quát của nghịch đảo khi ma trận không khả nghịch hoặc thậm chí không vuông. Trong khuôn khổ bài viết này, tôi xin phép được lược bỏ phần này, nếu các bạn thực sự quan tâm, tôi sẽ viết một bài khác chỉ nói về giả nghịch đảo. Xem thêm: <a href="http://www.sci.utah.edu/~gerig/CS6640-F2012/Materials/pseudoinverse-cis61009sl10.pdf">Least Squares, Pseudo-Inverses, PCA &amp; SVD</a>.</em>)</p>

<p>Với khái niệm giả nghịch đảo, điểm tối ưu của bài toán Linear Regression có dạng:</p>

<p>\[
\mathbf{w} = \mathbf{A}^{\dagger}\mathbf{b} = (\mathbf{\bar{X}}^T\mathbf{\bar{X}})^{\dagger} \mathbf{\bar{X}}^T\mathbf{y}
~~~ (5)
\]</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-vi-du-tren-python"></a></p>

<h2 id="3-ví-dụ-trên-python">3. Ví dụ trên Python</h2>

<!-- ========================== New Heading ==================== -->
<p><a name="-bai-toan"></a></p>

<h3 id="31-bài-toán">3.1. Bài toán</h3>

<p>Trong phần này, tôi sẽ chọn một ví dụ đơn giản về việc giải bài toán Linear Regression trong Python. Tôi cũng sẽ so sánh nghiệm của bài toán khi giải theo phương trình \((5) \) và nghiệm tìm được khi dùng thư viện <a href="http://scikit-learn.org/stable/">scikit-learn</a> của Python. (<em>Đây là thư viện Machine Learning được sử dụng rộng rãi trong Python</em>). Trong ví dụ này, dữ liệu đầu vào chỉ có 1 giá trị (1 chiều) để thuận tiện cho việc minh hoạ trong mặt phẳng.</p>

<p>Chúng ta có 1 bảng dữ liệu về chiều cao và cân nặng của 15 người như dưới đây:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Chiều cao (cm)</th>
      <th style="text-align: center">Cân nặng (kg)</th>
      <th style="text-align: center">Chiều cao (cm)</th>
      <th style="text-align: center">Cân nặng (kg)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">147</td>
      <td style="text-align: center">49</td>
      <td style="text-align: center">168</td>
      <td style="text-align: center">60</td>
    </tr>
    <tr>
      <td style="text-align: center">150</td>
      <td style="text-align: center">50</td>
      <td style="text-align: center">170</td>
      <td style="text-align: center">72</td>
    </tr>
    <tr>
      <td style="text-align: center">153</td>
      <td style="text-align: center">51</td>
      <td style="text-align: center">173</td>
      <td style="text-align: center">63</td>
    </tr>
    <tr>
      <td style="text-align: center">155</td>
      <td style="text-align: center">52</td>
      <td style="text-align: center">175</td>
      <td style="text-align: center">64</td>
    </tr>
    <tr>
      <td style="text-align: center">158</td>
      <td style="text-align: center">54</td>
      <td style="text-align: center">178</td>
      <td style="text-align: center">66</td>
    </tr>
    <tr>
      <td style="text-align: center">160</td>
      <td style="text-align: center">56</td>
      <td style="text-align: center">180</td>
      <td style="text-align: center">67</td>
    </tr>
    <tr>
      <td style="text-align: center">163</td>
      <td style="text-align: center">58</td>
      <td style="text-align: center">183</td>
      <td style="text-align: center">68</td>
    </tr>
    <tr>
      <td style="text-align: center">165</td>
      <td style="text-align: center">59</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<p>Bài toán đặt ra là: liệu có thể dự đoán cân nặng của một người dựa vào chiều cao của họ không? (<em>Trên thực tế, tất nhiên là không, vì cân nặng còn phụ thuộc vào nhiều yếu tố khác nữa, thể tích chẳng hạn</em>). Vì blog này nói về các thuật toán Machine Learning đơn giản nên tôi sẽ giả sử rằng chúng ta có thể dự đoán được.</p>

<p>Chúng ta có thể thấy là cân nặng sẽ tỉ lệ thuận với chiều cao (càng cao càng nặng), nên có thể sử dụng Linear Regression model cho việc dự đoán này. Để kiểm tra độ chính xác của model tìm được, chúng ta sẽ giữ lại cột 155 và 160 cm để kiểm thử, các cột còn lại được sử dụng để huấn luyện (train) model.</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-hien-thi-du-lieu-tren-do-thi"></a></p>

<h3 id="32-hiển-thị-dữ-liệu-trên-đồ-thị">3.2. Hiển thị dữ liệu trên đồ thị</h3>
<p>Trước tiên, chúng ta cần có hai thư viện <a href="http://www.numpy.org/">numpy</a> cho đại số tuyến tính và <a href="http://matplotlib.org/">matplotlib</a> cho việc vẽ hình.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># To support both python 2 and python 3
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div>

<p>Tiếp theo, chúng ta khai báo và biểu diễn dữ liệu trên một đồ thị.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># height (cm)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">147</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">158</span><span class="p">,</span> <span class="mi">163</span><span class="p">,</span> <span class="mi">165</span><span class="p">,</span> <span class="mi">168</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="mi">173</span><span class="p">,</span> <span class="mi">175</span><span class="p">,</span> <span class="mi">178</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">183</span><span class="p">]]).</span><span class="n">T</span>
<span class="c1"># weight (kg)
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span>  <span class="mi">54</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">68</span><span class="p">]]).</span><span class="n">T</span>
<span class="c1"># Visualize data 
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">140</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">75</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Height (cm)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Weight (kg)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<!-- ![png](/assets/LR/output_3_0.png) -->
<div class="imgcap">
<img src="/assets/LR/output_3_0.png" align="center" />
</div>

<p>Từ đồ thị này ta thấy rằng dữ liệu được sắp xếp gần như theo 1 đường thẳng, vậy mô hình Linear Regression nhiều khả năng sẽ cho kết quả tốt:</p>

<p>(cân nặng) = <code class="language-plaintext highlighter-rouge">w_1</code>*(chiều cao) + <code class="language-plaintext highlighter-rouge">w_0</code></p>

<!-- ========================== New Heading ==================== -->
<p><a name="-nghiem-theo-cong-thuc"></a></p>

<h3 id="33-nghiệm-theo-công-thức">3.3. Nghiệm theo công thức</h3>

<p>Tiếp theo, chúng ta sẽ tính toán các hệ số <code class="language-plaintext highlighter-rouge">w_1</code> và <code class="language-plaintext highlighter-rouge">w_0</code> dựa vào công thức \((5)\). Chú ý: giả nghịch đảo của một ma trận <code class="language-plaintext highlighter-rouge">A</code> trong Python sẽ được tính bằng <code class="language-plaintext highlighter-rouge">numpy.linalg.pinv(A)</code>, <code class="language-plaintext highlighter-rouge">pinv</code> là từ viết tắt của <em>pseudo inverse</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Building Xbar 
</span><span class="n">one</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Xbar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">one</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calculating weights of the fitting line 
</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xbar</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Xbar</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xbar</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'w = '</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="c1"># Preparing the fitting line 
</span><span class="n">w_0</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">w_1</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">145</span><span class="p">,</span> <span class="mi">185</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">w_0</span> <span class="o">+</span> <span class="n">w_1</span><span class="o">*</span><span class="n">x0</span>

<span class="c1"># Drawing the fitting line 
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>     <span class="c1"># data 
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>               <span class="c1"># the fitting line
</span><span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">140</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">75</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Height (cm)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Weight (kg)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w =  [[-33.73541021]
 [  0.55920496]]
</code></pre></div></div>

<!-- ![pnet/asset/LR/output_5_1.png) -->
<div class="imgcap">
<img src="/assets/LR/output_5_1.png" align="center" />
</div>

<p>Từ đồ thị bên trên ta thấy rằng các điểm dữ liệu màu đỏ nằm khá gần đường thẳng dự đoán màu xanh. Vậy mô hình Linear Regression hoạt động tốt với tập dữ liệu <em>training</em>. Bây giờ, chúng ta sử dụng mô hình này để dự đoán cân nặng của hai người có chiều cao 155 và 160 cm mà chúng ta đã không dùng khi tính toán nghiệm.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y1</span> <span class="o">=</span> <span class="n">w_1</span><span class="o">*</span><span class="mi">155</span> <span class="o">+</span> <span class="n">w_0</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">w_1</span><span class="o">*</span><span class="mi">160</span> <span class="o">+</span> <span class="n">w_0</span>

<span class="k">print</span><span class="p">(</span> <span class="sa">u</span><span class="s">'Predict weight of person with height 155 cm: %.2f (kg), real number: 52 (kg)'</span>  <span class="o">%</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span> <span class="p">)</span>
<span class="k">print</span><span class="p">(</span> <span class="sa">u</span><span class="s">'Predict weight of person with height 160 cm: %.2f (kg), real number: 56 (kg)'</span>  <span class="o">%</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span> <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predict weight of person with height 155 cm: 52.94 (kg), real number: 52 (kg)
Predict weight of person with height 160 cm: 55.74 (kg), real number: 56 (kg)
</code></pre></div></div>

<p>Chúng ta thấy rằng kết quả dự đoán khá gần với số liệu thực tế.</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-nghiem-theo-thu-vien-scikit-learn"></a></p>

<h3 id="34-nghiệm-theo-thư-viện-scikit-learn">3.4. Nghiệm theo thư viện scikit-learn</h3>

<p>Tiếp theo, chúng ta sẽ sử dụng thư viện scikit-learn của Python để tìm nghiệm.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">linear_model</span>

<span class="c1"># fit the model by Linear Regression
</span><span class="n">regr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># fit_intercept = False for calculating the bias
</span><span class="n">regr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xbar</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Compare two results
</span><span class="k">print</span><span class="p">(</span> <span class="s">'Solution found by scikit-learn  : '</span><span class="p">,</span> <span class="n">regr</span><span class="p">.</span><span class="n">coef_</span> <span class="p">)</span>
<span class="k">print</span><span class="p">(</span> <span class="s">'Solution found by (5): '</span><span class="p">,</span> <span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Solution found by scikit-learn  :  [[  -33.73541021 0.55920496]]
    Solution found by (5):  [[  -33.73541021 0.55920496 ]]
</code></pre></div></div>

<p>Chúng ta thấy rằng hai kết quả thu được như nhau! (<em>Nghĩa là tôi đã không mắc lỗi nào trong cách tìm nghiệm ở phần trên</em>)</p>

<p><a href="https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/LR/LR.ipynb">Source code Jupyter Notebook cho bài này.</a></p>

<!-- ========================== New Heading ==================== -->
<p><a name="-thao-luan"></a></p>

<h2 id="4-thảo-luận">4. Thảo luận</h2>

<!-- ========================== New Heading ==================== -->
<p><a name="-cac-bai-toan-co-the-giai-bang-linear-regression"></a></p>

<h3 id="41-các-bài-toán-có-thể-giải-bằng-linear-regression">4.1. Các bài toán có thể giải bằng Linear Regression</h3>
<p>Hàm số \(y \approx f(\mathbf{x})= \mathbf{w}^T\mathbf{x}\) là một hàm tuyến tính theo cả \( \mathbf{w}\) và \(\mathbf{x}\). Trên thực tế, Linear Regression có thể áp dụng cho các mô hình chỉ cần tuyến tính theo \(\mathbf{w}\). Ví dụ:
\[
y \approx w_1 x_1 + w_2 x_2 + w_3 x_1^2 + 
\]
\[
+w_4 \sin(x_2) + w_5 x_1x_2 + w_0
\]
là một hàm tuyến tính theo \(\mathbf{w}\) và vì vậy cũng có thể được giải bằng Linear Regression. Với mỗi dữ liệu đầu vào \(\mathbf{x}=[x_1; x_2] \), chúng ta tính toán dữ liệu mới \(\tilde{\mathbf{x}} = [x_1, x_2, x_1^2, \sin(x_2), x_1x_2]\) (đọc là <em>x tilde</em> trong tiếng Anh) rồi áp dụng Linear Regression với dữ liệu mới này.</p>

<p>Xem thêm ví dụ về <a href="http://www.varsitytutors.com/hotmath/hotmath_help/topics/quadratic-regression">Quadratic Regression</a> (Hồi Quy Bậc Hai).</p>
<div class="imgcap">
<div>
    <img src="http://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/quadratic-regression/f-qr-1-1.gif" width="300" />&lt;/a&gt;
</div>
<div class="thecap"> Quadratic Regression (Nguồn: <a href="http://www.varsitytutors.com/hotmath/hotmath_help/topics/quadratic-regression"> Quadratic Regression</a>) <br /></div>
</div>

<!-- ========================== New Heading ==================== -->
<p><a name="-han-che-cua-linear-regression"></a></p>

<h3 id="42-hạn-chế-của-linear-regression">4.2. Hạn chế của Linear Regression</h3>

<p>Hạn chế đầu tiên của Linear Regression là nó rất <strong>nhạy cảm với nhiễu</strong> (sensitive to noise). Trong ví dụ về mối quan hệ giữa chiều cao và cân nặng bên trên, nếu có chỉ
một cặp dữ liệu <em>nhiễu</em> (150 cm, 90kg) thì kết quả sẽ sai khác đi rất nhiều. Xem hình dưới đây:</p>
<div class="imgcap">
<img src="/assets/LR/output_13_1.png" align="center" />
</div>

<p>Vì vậy, trước khi thực hiện Linear Regression, các nhiễu (<em>outlier</em>) cần
 phải được loại bỏ. Bước này được gọi là tiền xử lý (pre-processing).</p>

<p>Hạn chế thứ hai của Linear Regression là nó <strong>không biễu diễn được các mô hình phức tạp</strong>. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng nếu quan hệ giữa <em>outcome</em> và <em>input</em> không nhất thiết phải là tuyến tính, nhưng mối quan hệ này vẫn đơn giản nhiều so với các mô hình thực tế. Hơn nữa, chúng ta sẽ tự hỏi: làm thế nào để xác định được các hàm \(x_1^2, \sin(x_2), x_1x_2\) như ở trên?!</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-cac-phuong-phap-toi-uu"></a></p>

<h3 id="43-các-phương-pháp-tối-ưu">4.3. Các phương pháp tối ưu</h3>
<p>Linear Regression là một mô hình đơn giản, lời giải cho phương trình đạo hàm bằng 0 cũng khá đơn giản. <em>Trong hầu hết các trường hợp, chúng ta không thể giải được phương trình đạo hàm bằng 0.</em></p>

<p>Nhưng có một điều chúng ta nên nhớ, <strong>còn tính được đạo hàm là còn có hy vọng</strong>.</p>

<!-- ========================== New Heading ==================== -->
<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-tài-liệu-tham-khảo">5. Tài liệu tham khảo</h2>

<ol>
  <li><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression - Wikipedia</a></li>
  <li><a href="http://machinelearningmastery.com/simple-linear-regression-tutorial-for-machine-learning/">Simple Linear Regression Tutorial for Machine Learning</a></li>
  <li><a href="http://www.sci.utah.edu/~gerig/CS6640-F2012/Materials/pseudoinverse-cis61009sl10.pdf">Least Squares, Pseudo-Inverses, PCA &amp; SVD</a></li>
</ol>


</div>

<hr> 
<em>Nếu có câu hỏi, Bạn có thể để lại comment bên dưới hoặc trên <a href = "https://www.facebook.com/groups/257768141347267/">Forum</a> để nhận được câu trả lời sớm hơn.</em>
<br>
<em>Bạn đọc có thể ủng hộ blog qua <a href = "/buymeacoffee/">'Buy me a cofee'</a> ở góc trên bên trái của blog.
</em>

<br>
<em>Tôi vừa hoàn thành cuốn ebook 'Machine Learning cơ bản', bạn có thể đặt sách <a href = "/ebook/">tại đây</a>.

Cảm ơn bạn.</em>

<hr>

<!-- previous and next posts -->
<div class="PageNavigation">
   
      <a class="prev" style = "color: #204081;" href="/2016/12/27/categories/">&laquo; Bài 2: Phân nhóm các thuật toán Machine Learning</a>
   
   
      <a class="next" style = "float: right; color: #204081;" href="/2017/01/01/kmeans/">Bài 4: K-means Clustering &raquo;</a>
   
</div>


<!-- disqus comments -->

      <hr>
   
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname  = 'tiepvu';
  var disqus_identifier = 'tiepvupsu.github.io' + '/2016/12/28/linearregression/';

  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    <script id="dsq-count-scr" src="//tiepvu.disqus.com/count.js" async></script>





   <!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11213317; 
var sc_invisible=0; 
var sc_security="31bb1f61"; 
var sc_text=2; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("Total visits: <sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'> </"+"script>");
</script>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11213317/0/31bb1f61/0/" alt="web
analytics"></a> </div></noscript>
<!-- End of StatCounter Code for Default Guide -->

<!-- <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- 
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?...">
</script> -->
	        </div>
	        <div class="col-md-2 hidden-xs hidden-sm">
	        	
          <!-- Google search -->
<!--           <table border="0">
          <div id = "top-widget" style="width: 252px; margin-left: -13.5px; margin-top: -10px; margin-bottom: -15px;">
         <script>
           (function() {
             var cx = '012053542614118746585:ktgei4l2oek';
             var gcse = document.createElement('script');
             gcse.type = 'text/javascript';
             gcse.async = true;
             gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
             var s = document.getElementsByTagName('script')[0];
             s.parentNode.insertBefore(gcse, s);
           })();
         </script>
         <gcse:search></gcse:search>
          </div>
          </table> -->

          

         <!--  
          <nav>
          
            <div class="header">Latest by category</div>
            <ul>
              
                
              
                
                  
                    <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif; color: #204081;" href="/2016/12/28/linearregression/">Bài 3: Linear Regression</a></li>
                  
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
            </ul>
          </nav>
          



          <nav>
            <div class="header">Latest</div>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/lifesofar2/">Con đường học PhD của tôi</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/10/03/conv2d">Bài 37: Tích chập hai chiều</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/09/11/forum/">Giới thiệu Diễn đàn Machine Learning cơ bản</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/07/06/deeplearning/">Bài 36. Giới thiệu về Keras</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/06/22/deeplearning/">Bài 35: Lược sử Deep Learning</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/03/22/phuonghoagiang/">Bạn đọc viết: Con đường học Khoa học dữ liệu của một sinh viên Kinh tế</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2018/01/14/id3/">Bài 34: Decision Trees (1): Iterative Dichotomiser 3</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/08/31/evaluation/">Bài 33: Các phương pháp đánh giá một hệ thống phân lớp</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/10/20/fundaml_vectors/">FundaML 3: Làm việc với các mảng ngẫu nhiên</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/10/20/fundaml_matrices/">FundaML 2: Làm việc với ma trận</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/10/12/fundaml_vectors/">FundaML 1: Làm việc với mảng một chiều</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/09/24/fundaml/">Giới thiệu trang web FundaML.com</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/08/08/nbc/">Bài 32: Naive Bayes Classifier</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/08/05/phdlife/">PhD life 1: Quá trình viết và nhận xét các bài báo khoa học</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/07/17/mlemap/">Bài 31: Maximum Likelihood và Maximum A Posteriori estimation</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/lifesofar/">Con đường học Toán của tôi</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/07/09/prob/">Bài 30: Ôn tập Xác Suất cho Machine Learning</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/07/02/tl/">Quick Note 2: Transfer Learning cho bài toán phân loại ảnh</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/06/30/lda/">Bài 29: Linear Discriminant Analysis</a></li>
              
                <li><a style="text-align: left; font-family: 'Open Sans Condensed', sans-serif;color: #204081"  href="/2017/06/22/qns1/">Quick Notes 1</a></li>
              
            </ul>
          </nav> -->

          <aside class = "social">
          <div class = "header">Share</div>
          <div class="share-page">
    <!-- <b>Share this on:</b>  <br> -->

    <!-- Facebook -->
    <!-- <a href="https://facebook.com/sharer/sharer.php?u=https://machinelearningcoban.com/2016/12/28/linearregression/" rel="nofollow" target="_blank" title="Share on Facebook"><img src = "/assets/images/facebook.png" width="25"></a> -->

    <div class="fb-share-button" data-href="https://machinelearningcoban.com/2016/12/28/linearregression/" data-layout="button_count" data-size="small" data-mobile-iframe="true"><a class="fb-xfbml-parse-ignore" target="_blank" href="https://facebook.com/sharer/sharer.php?u=https://machinelearningcoban.com/2016/12/28/linearregression/">Share</a></div>


    <!-- Twitter -->
    <!-- <a href="https://twitter.com/intent/tweet?text=Bài 3: Linear Regression&url=https://machinelearningcoban.com/2016/12/28/linearregression/&via=&related=" rel="nofollow" target="_blank" title="Share on Twitter" width="25" ><img src = "/assets/images/twitter.png" width="25"></a> -->

    <!-- Google -->
    <!-- <a href="https://plus.google.com/share?url=https://machinelearningcoban.com/2016/12/28/linearregression/" rel="nofollow" target="_blank" title="Share on Google+"><img src = "/assets/images/google.png" width="25"></a> -->

    
    <!-- LinkedIn -->
    <!-- <a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://machinelearningcoban.com/2016/12/28/linearregression/" target="_blank"> <img src="/assets/images/linkedin.png" alt="LinkedIn" width="25"/> -->
    <!-- </a> -->

    <!-- Email -->
    <a href="/cdn-cgi/l/email-protection#655a3610070f00061158360c0815090045360d04170045271011110a0b16430408155e270a011c582c405755160412405755110d0c16405755040b01405755110d0a10020d114057550a034057551c0a1044405755450d111115165f4a4a0804060d0c0b00090004170b0c0b02060a07040b4b060a084a575554534a54574a575d4a090c0b000417170002170016160c0a0b4a">
        <img src="/assets/images/email.png" alt="Email" width="25"/>
    </a>
    <!-- Print -->
    <a href="javascript:;" onclick="window.print()">
        <img src="/assets/images/print.png" alt="Print" width="25"/>
    </a>
   </div>
          </aside>
          
           <nav>
            <div class="header">Diễn đàn</div>
            <a   href="https://forum.machinelearningcoban.com">
            <img width="100%" src="/assets/latex/new_logo9-2.png"/>  </a>
          </nav>
          
          <nav>
            <div class="header">Interactive Learning</div>
            <a   href="https://fundaml.com">
            <img width="100%" src="/images/fundaml_web.png"/>  </a>
          </nav>

          <nav>
          <div class = "header" with = "100%">Facebook page</div>
          <!-- <a href = "https://www.facebook.com/machinelearningbasicvn/" target="_blank" title="Follow us"><img src = "/assets/images/facebook.png" width="30"></a> -->
          <!-- facebook page -->

         <div class="fb-page" data-href="https://www.facebook.com/machinelearningbasicvn/" data-width="250" data-small-header="false" data-adapt-container-width="true" data-hide-cover="false" data-show-facepile="false"><blockquote cite="https://www.facebook.com/machinelearningbasicvn/" class="fb-xfbml-parse-ignore" ><a style = "color: #204081" href="https://www.facebook.com/machinelearningbasicvn/">Machine Learning cơ bản</a></blockquote></div>
          <!--end facebook page -->

          </nav>
          <nav>
            <div class="header">Facebook group</div>
            <a   href="https://www.facebook.com/groups/257768141347267/">
            <img width="100%" src="/assets/14_mlp/multi_layers.png"/>  </a>
          </nav>
          


          <nav>

          <div class="header">Recommended books</div>
            <ul>
              <li> <a style="text-align: left; color: #074B80;" href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjd7Y_Q-tzTAhVISyYKHUXyCekQFggvMAA&url=http%3A%2F%2Fusers.isr.ist.utl.pt%2F~wurmd%2FLivros%2Fschool%2FBishop%2520-%2520Pattern%2520Recognition%2520And%2520Machine%2520Learning%2520-%2520Springer%2520%25202006.pdf&usg=AFQjCNEVQzQ_dEpxG4P7NamTWUXnVXzCng&sig2=H1WVtom4rq3uh8UfbGX4oA">"Pattern recognition and Machine Learning.", C. Bishop </a></li>

              <li> <a style="text-align: left; color: #074B80;" href="https://github.com/tpn/pdfs/blob/master/The%20Elements%20of%20Statistical%20Learning%20-%20Data%20Mining%2C%20Inference%20and%20Prediction%20-%202nd%20Edition%20(ESLII_print4).pdf">"The Elements of Statistical Learning", T. Hastie et al.  </a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://www.computervisionmodels.com/">"Computer Vision:  Models, Learning, and Inference", Simon J.D. Prince </a></li>

              <li> <a style="text-align: left; color: #074B80;" href="https://stanford.edu/~boyd/cvxbook/">"Convex Optimization", Boyd and Vandenberghe</a></li>

            </ul>
          </nav>

          <nav>
          <div class="header">Recommended courses</div>

          <ul>
              <li> <a style="text-align: left; color: #074B80;" href="https://www.coursera.org/learn/machine-learning?utm_source=gg&utm_medium=sem&campaignid=693373197&adgroupid=36745103515&device=c&keyword=machine%20learning%20andrew%20ng&matchtype=e&network=g&devicemodel=&adpostion=1t1&creativeid=156061453588&hide_mobile_promo&gclid=Cj0KEQjwt6fHBRDtm9O8xPPHq4gBEiQAdxotvNEC6uHwKB5Ik_W87b9mo-zTkmj9ietB4sI8-WWmc5UaAi6a8P8HAQ">"Machine Learning", Andrew Ng </a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://web.stanford.edu/class/cs224n/">CS224n: Natural Language Processing with Deep Learning</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a></li>           

              <li> <a style="text-align: left; color: #074B80;" href="http://web.stanford.edu/class/cs246/">CS246: Mining Massive Data Sets</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://web.stanford.edu/class/cs20si/syllabus.html">CS20SI: Tensorflow for Deep Learning Research </a></li>

              <li> <a style="text-align: left; color: #074B80;" href="https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-10">Introduction to Computer Science and Programming Using Python</a></li>           

            </ul>
          </nav>

          <nav>
          <div class="header">Others</div>
          <ul>
              <li> <a style="text-align: left; color: #074B80;" href="https://github.com/ZuzooVn/machine-learning-for-software-engineers">Top-down learning path: Machine Learning for Software Engineers</a></li>
              
              <li> <a style="text-align: left; color: #074B80;" href="/2017/02/02/howdoIcreatethisblog/">Blog này được tạo như thế nào?</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://thepresentwriter.com/chung-toi-da-apply-va-hoc-tien-si-nhu-the-nao-phan-1/">Chúng tôi đã apply và học tiến sỹ như thế nào? (1/2)</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://thepresentwriter.com/chung-toi-da-apply-va-hoc-tien-si-nhu-the-nao-phan-2/">Chúng tôi đã apply và học tiến sỹ như thế nào? (2/2)</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="http://machinelearningmastery.com/inspirational-applications-deep-learning/">8 Inspirational Applications of Deep Learning</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf">Matrix calculus</a></li>

              <li> <a style="text-align: left; color: #074B80;" href="https://github.com/aymericdamien/TensorFlow-Examples">TensorFlow-Examples</a></li>
              
              <li> <a style="text-align: left; color: #074B80;" href="https://www.forbes.com/sites/quora/2017/04/05/eight-easy-steps-to-get-started-learning-artificial-intelligence/#53c29fa5b117">Eight Easy Steps To Get Started Learning Artificial Intelligence</a></li>
              <li> <a style="text-align: left; color: #074B80;" href="https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html">The 9 Deep Learning Papers You Need To Know About</a></li>

                     

            </ul>
          </nav>
          <!-- <img style = "transform: scaleX(1); width:100%; margin-left:00px;position: absolute;" src = "/images/mai.jpg"> -->
         
         <!--   
            <nav>
              <div class="header">Previous by date</div>
              <ul>
                <li><a style="text-align: left; font-family: 'Roboto Condensed', sans-serif; color: #074B80;" href="/2016/12/27/categories/">Bài 2: Phân nhóm các thuật toán Machine Learning</a></li>
              </ul>
            </nav>
           
           
            <nav>
              <div class="header">Next by date</div>
              <ul>
                <li><a style="text-align: left; font-family: 'Roboto Condensed', sans-serif; color: #204081;" href="/2017/01/01/kmeans/">Bài 4: K-means Clustering</a></li>
              </ul>
            </nav>
            -->
	        <!-- <img style = "transform: scaleX(1); width:250%; margin-left:-100px;" src = "/images/dao.jpg"> -->
	        <!-- <a href ="https://www.facebook.com/masspvn/?fref=nf&pnref=story">MaSSP</a> -->
	        </div>
      	</div>
    </div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body>

</html>
